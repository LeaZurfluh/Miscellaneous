{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PREREQUISITES:\n",
    "    - Get an environment variable called GOOGLE_CREDS with the json of credentials\n",
    "        used to access google API (cf. 1Password)\n",
    "    - Run pip install all the packages listed in the import section if not already done \n",
    "        * pip install google \n",
    "        * pip install googleapiclient\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' METHODS:\\n    - get_dataframe(spreadsheet_id, worksheet_name, range_name, headers=1)\\n    - write_dataframe(df, spreadsheet_id, worksheet_name, row=1, col=1)\\n    - clear_worksheet(spreadsheet_id, worksheet_name)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' METHODS:\n",
    "    - get_dataframe(spreadsheet_id, worksheet_name, range_name, headers=1)\n",
    "    - write_dataframe(df, spreadsheet_id, worksheet_name, row=1, col=1)\n",
    "    - clear_worksheet(spreadsheet_id, worksheet_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "\n",
    "# If modifying these scopes, delete the file token.json.\n",
    "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\"]\n",
    "\n",
    "class GoogleSheetData:\n",
    "    \"\"\" Class that handles data requests about google sheets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" Connects to gsheet using env variable GOOGLE_CREDS (1st time connecting)\n",
    "        or local file token.json if exists (subsequent connections).    \n",
    "        \"\"\"\n",
    "\n",
    "        credentials = None\n",
    "        # The file token.json stores the user's access and refresh tokens, and is\n",
    "        # created automatically when the authorization flow completes for the first\n",
    "        # time.\n",
    "        if os.path.exists(\"token.json\"):\n",
    "            credentials = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "\n",
    "        # If there are no (valid) credentials available, let the user log in.\n",
    "        if not credentials or not credentials.valid:\n",
    "            if credentials and credentials.expired and credentials.refresh_token:\n",
    "                credentials.refresh(Request())\n",
    "            else:\n",
    "                config = json.loads(os.environ['GOOGLE_CREDS'])\n",
    "                flow = InstalledAppFlow.from_client_config(\n",
    "                        config, SCOPES)\n",
    "\n",
    "                credentials = flow.run_local_server(port=0)\n",
    "\n",
    "            # Save the credentials for the next run\n",
    "            with open(\"token.json\", \"w\") as token:\n",
    "                token.write(credentials.to_json())\n",
    "\n",
    "        self.creds = credentials\n",
    "        return print('Connected to GSheets')\n",
    "\n",
    "\n",
    "    def get_dataframe(self, spreadsheet_id, worksheet_name, range_name, headers=1):\n",
    "        \"\"\" Returns pandas dataframe from a spreadsheet.\n",
    "\n",
    "            :param spreadsheet_id:    ID of the spreadhsheet, found in its URL: str\n",
    "            :param worksheet_name:    name of worksheet e.g. \"Sheet1\": str\n",
    "            :param range_name:        range to take into account e.g. \"A1:E15\": str\n",
    "            :param headers:           whether selection has headers (1) or not (0). Default 1: int\n",
    "\n",
    "            :return:                  pandas dataframe of the selection: df\n",
    "        \"\"\"\n",
    "\n",
    "        total_range = worksheet_name + '!' + range_name\n",
    "\n",
    "        try:\n",
    "            service = build(\"sheets\", \"v4\", credentials=self.creds)\n",
    "\n",
    "            # Call the Sheets API\n",
    "            sheet = service.spreadsheets()\n",
    "            result = (\n",
    "                sheet.values()\n",
    "                .get(spreadsheetId=spreadsheet_id, range=total_range)\n",
    "                .execute()\n",
    "            )\n",
    "            values = result.get(\"values\", [])\n",
    "\n",
    "            if not values:\n",
    "                print(\"No data found.\")\n",
    "                return\n",
    "            \n",
    "            if headers > 0:\n",
    "                df = pd.DataFrame(values[1:], columns=values[0])\n",
    "            else:\n",
    "                df = pd.DataFrame(values)\n",
    "\n",
    "            return df\n",
    "\n",
    "        except HttpError as err:\n",
    "            print(err)\n",
    "\n",
    "\n",
    "    def write_dataframe(self, df, spreadsheet_id, worksheet_name, row=1, col=1):\n",
    "        \"\"\" Writes a dataframe into a google worksheet.\n",
    "\n",
    "            :param df:                  pandas dataframe to write to GSheet: df\n",
    "            :param spreadsheet_id:      ID of the spreadhsheet, found in its URL: str\n",
    "            :param worksheet_name:      name of worksheet, e.g. \"Sheet1\": str\n",
    "            :param row:                 row number where df is going to be written, default 1: int\n",
    "            :param col:                 column number where df is going to be written, default 1: int\n",
    "            \n",
    "            :return:                    dict of spreadsheet & range that has been updated, with which cells have been written on: dict\n",
    "        \"\"\"\n",
    "\n",
    "        col_letter_start = chr(ord('@') + col) # Transforms a column nb into a letter, e.g. 2 -> B\n",
    "        row_number_start = row\n",
    "\n",
    "        range_name = col_letter_start + str(row_number_start)\n",
    "        total_range = worksheet_name + '!' + range_name\n",
    "\n",
    "        try:\n",
    "            service = build(\"sheets\", \"v4\", credentials=self.creds)\n",
    "\n",
    "            col_names = [df.columns.values.tolist()]\n",
    "            values = col_names + df.values.tolist()\n",
    "\n",
    "            body = {\"values\": values}\n",
    "\n",
    "            result = (\n",
    "                service.spreadsheets()\n",
    "                .values()\n",
    "                .update(\n",
    "                    spreadsheetId=spreadsheet_id,\n",
    "                    range=total_range,\n",
    "                    valueInputOption=\"USER_ENTERED\",\n",
    "                    body=body,\n",
    "                )\n",
    "                .execute()\n",
    "            )\n",
    "            return result\n",
    "        \n",
    "        except HttpError as error:\n",
    "            print(f\"An error occurred: {error}\")\n",
    "            return error\n",
    "        \n",
    "\n",
    "    def clear_worksheet(self, spreadsheet_id, worksheet_name):\n",
    "        \"\"\" Clears data from a worksheet.\n",
    "\n",
    "            :param spreadsheet_id:      ID of the spreadhsheet, found in its URL: str\n",
    "            :param worksheet_name:      name of worksheet, e.g. \"Sheet1\": str\n",
    "\n",
    "            :return:                    dict of spreadsheet & range that has been cleared: dict\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            service = build(\"sheets\", \"v4\", credentials=self.creds)\n",
    "\n",
    "            result = (\n",
    "                service.spreadsheets()\n",
    "                .values()\n",
    "                .clear(\n",
    "                    spreadsheetId=spreadsheet_id,\n",
    "                    range=worksheet_name,\n",
    "                )\n",
    "                .execute()\n",
    "            )\n",
    "            return result\n",
    "        \n",
    "        except HttpError as error:\n",
    "            print(f\"An error occurred: {error}\")\n",
    "            return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GoogleSheetData()\n",
    "\n",
    "# Get dataframe \n",
    "df = gs.get_dataframe(\"1R3Bw9aUNvJm-1HxPTYLJyDPT9Vt0mINwQI2bq1HMfxA\", \"Sheet1\", \"A1:B100\")\n",
    "\n",
    "# Write dataframe \n",
    "gs.write_dataframe(df, \"1R3Bw9aUNvJm-1HxPTYLJyDPT9Vt0mINwQI2bq1HMfxA\", \"Sheet2\")\n",
    "\n",
    "# Clear worksheet \n",
    "gs.clear_worksheet(\"1R3Bw9aUNvJm-1HxPTYLJyDPT9Vt0mINwQI2bq1HMfxA\", \"Sheet2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/leazurfluh/Downloads/DO NOT EDIT -Data Recon 23 & 24/2023 CSV Files/2023_bumble_marketing_spend_editJan24_no_meta_college_refactored.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_files_2023 = '/Users/leazurfluh/Downloads/DO NOT EDIT -Data Recon 23 & 24/refactored_files/2023/'\n",
    "path_files_2024 = '/Users/leazurfluh/Downloads/DO NOT EDIT -Data Recon 23 & 24/refactored_files/2024/'\n",
    "suffix = '_refactored.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {\n",
    "    '2023_bumble_marketing_spend_editJan24_no_meta_college': path_files_2023,\n",
    "    'Restated & Net New MMM Data - College Ambassador 2023': path_files_2023,\n",
    "    '2023 Meta Restated': path_files_2023,\n",
    "    '2024 Meta Restated': path_files_2024,\n",
    "    'AB Updated MMM H1 2024 US Data - NYT': path_files_2024,\n",
    "    'AB Updated MMM H1 2024 US Data - Snapchat': path_files_2024,\n",
    "    'AB Updated MMM H1 2024 US Data - Vox': path_files_2024,\n",
    "    'AB Updated MMM H1 2024 US Data - YouTube via MiQ': path_files_2024,\n",
    "    'AB Updated MMM H1 2024 US Data - iHeart': path_files_2024,\n",
    "    'US_Bumble_SPAN_2024 AP': path_files_2024,\n",
    "    'US_Bumble_Dating Sunday_January 2024': path_files_2024,\n",
    "    'US_Bumble_Audio_Q2 2024': path_files_2024,\n",
    "    'US_Bumble_Anything Goes_Dating Exclusivity_2024 AP': path_files_2024,\n",
    "    'IAT_Bumble_Q4_US_2024_MM': path_files_2024,\n",
    "    'Havas_Bumble_Q3_US_2024_MM': path_files_2024,\n",
    "    'Aug-Dec 2024 Havas Meta': path_files_2024,\n",
    "    'AB Updated MMM Q3 2024 US Data - TikTok': path_files_2024,\n",
    "    'Restated & Net New MMM Data - TikTok (1)': path_files_2024,\n",
    "    'AB Updated MMM H1 2024 US Data - TikTok': path_files_2024,\n",
    "    'AB Updated MMM H1 2024 US Data - Google (YouTube)': path_files_2024,\n",
    "    'AB Updated MMM H1 2024 US Data - CTV via MiQ (thru 6_30)': path_files_2024,\n",
    "    'AB Updated MMM Q3 2024 US Data - YouTube via Miq': path_files_2024,\n",
    "    'Restated & Net New MMM Data - Meme': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data -  Oct OOH': path_files_2024,\n",
    "    'Restated & Net New MMM Data - Influencer': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data - December CTV via MiQ': path_files_2024,\n",
    "    'AB Updated MMM Q3 2024 US Data - Uber': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data - Oct YouTube via MiQ': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data - Oct TikTok': path_files_2024,\n",
    "    'Restated & Net New MMM Data - City Marketing': path_files_2024,\n",
    "    'Restated & Net New MMM Data - Pinterest': path_files_2024,\n",
    "    'AB Updated MMM Q3 2024 US Data - OOH': path_files_2024,\n",
    "    'AB Updated MMM Q3 2024 US Data - CTV via MiQ': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data - Nov YouTube via MiQ': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data - December YouTube via MiQ': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data - Nov TikTok': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data - December TikTok': path_files_2024,\n",
    "    'Restated & Net New MMM Data - Culture': path_files_2024,\n",
    "    'Restated & Net New MMM Data - College Ambassador 2024': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data - December Snapchat': path_files_2024,\n",
    "    'Restated & Net New MMM Data - Vox': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data - Nov CTV via MiQ': path_files_2024,\n",
    "    'Restated & Net New MMM Data - OOH': path_files_2024,\n",
    "    'Restated & Net New MMM Data - Live Nation (OOH)': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data - December OOH': path_files_2024,\n",
    "    'AB Updated MMM Q4 2024 US Data - Nov OOH': path_files_2024,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(path_files_2023 + '2023_bumble_marketing_spend_editJan24_no_meta_college' + suffix)\n",
    "df2 = pd.read_csv(path_files_2024 + '2024 Meta Restated' + suffix)\n",
    "df3 = pd.read_csv(path_files_2023 + 'Restated & Net New MMM Data - College Ambassador 2023' + suffix)\n",
    "df4 = pd.read_csv(path_files_2024 + 'AB Updated MMM H1 2024 US Data - NYT' + suffix)\n",
    "df5 = pd.read_csv(path_files_2024 + 'AB Updated MMM H1 2024 US Data - Snapchat' + suffix)\n",
    "df6 = pd.read_csv(path_files_2024 + 'AB Updated MMM H1 2024 US Data - Vox' + suffix)\n",
    "df7 = pd.read_csv(path_files_2024 + 'AB Updated MMM H1 2024 US Data - YouTube via MiQ' + suffix)\n",
    "df8 = pd.read_csv(path_files_2024 + 'AB Updated MMM H1 2024 US Data - iHeart' + suffix)\n",
    "df9 = pd.read_csv(path_files_2023 + '2023 Meta Restated' + suffix)\n",
    "df10 = pd.read_csv(path_files_2024 + 'US_Bumble_SPAN_2024 AP' + suffix)\n",
    "df11 = pd.read_csv(path_files_2024 + 'US_Bumble_Dating Sunday_January 2024' + suffix)\n",
    "df12 = pd.read_csv(path_files_2024 + 'US_Bumble_Audio_Q2 2024' + suffix)\n",
    "df13 = pd.read_csv(path_files_2024 + 'US_Bumble_Anything Goes_Dating Exclusivity_2024 AP' + suffix)\n",
    "df14 = pd.read_csv(path_files_2024 + 'IAT_Bumble_Q4_US_2024_MM' + suffix)\n",
    "df15 = pd.read_csv(path_files_2024 + 'Havas_Bumble_Q3_US_2024_MM' + suffix)\n",
    "df16 = pd.read_csv(path_files_2024 + 'Aug-Dec 2024 Havas Meta' + suffix)\n",
    "df17 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q3 2024 US Data - TikTok' + suffix)\n",
    "df18 = pd.read_csv(path_files_2024 + 'Restated & Net New MMM Data - TikTok (1)' + suffix)\n",
    "df19 = pd.read_csv(path_files_2024 + 'AB Updated MMM H1 2024 US Data - TikTok' + suffix)\n",
    "df20 = pd.read_csv(path_files_2024 + 'AB Updated MMM H1 2024 US Data - Google (YouTube)' + suffix)\n",
    "df21 = pd.read_csv(path_files_2024 + 'AB Updated MMM H1 2024 US Data - CTV via MiQ (thru 6_30)' + suffix)\n",
    "df22 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q3 2024 US Data - YouTube via Miq' + suffix)\n",
    "df23 = pd.read_csv(path_files_2024 + 'Restated & Net New MMM Data - Meme' + suffix)\n",
    "df24 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data -  Oct OOH' + suffix)\n",
    "df25 = pd.read_csv(path_files_2024 + 'Restated & Net New MMM Data - Influencer' + suffix)\n",
    "df26 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data - December CTV via MiQ' + suffix)\n",
    "df27 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q3 2024 US Data - Uber' + suffix)\n",
    "df28 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data - Oct YouTube via MiQ' + suffix)\n",
    "df29 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data - Oct TikTok' + suffix)\n",
    "df30 = pd.read_csv(path_files_2024 + 'Restated & Net New MMM Data - City Marketing' + suffix)\n",
    "df31 = pd.read_csv(path_files_2024 + 'Restated & Net New MMM Data - Pinterest' + suffix)\n",
    "df32 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q3 2024 US Data - OOH' + suffix)\n",
    "df33 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q3 2024 US Data - CTV via MiQ' + suffix)\n",
    "df34 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data - Nov YouTube via MiQ' + suffix)\n",
    "df35 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data - December YouTube via MiQ' + suffix)\n",
    "df36 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data - Nov TikTok' + suffix)\n",
    "df37 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data - December TikTok' + suffix)\n",
    "df38 = pd.read_csv(path_files_2024 + 'Restated & Net New MMM Data - Culture' + suffix)\n",
    "df39 = pd.read_csv(path_files_2024 + 'Restated & Net New MMM Data - College Ambassador 2024' + suffix)\n",
    "df40 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data - December Snapchat' + suffix)\n",
    "df41 = pd.read_csv(path_files_2024 + 'Restated & Net New MMM Data - Vox' + suffix)\n",
    "df42 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data - Nov CTV via MiQ' + suffix)\n",
    "df43 = pd.read_csv(path_files_2024 + 'Restated & Net New MMM Data - OOH' + suffix)\n",
    "df44 = pd.read_csv(path_files_2024 + 'Restated & Net New MMM Data - Live Nation (OOH)' + suffix)\n",
    "df45 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data - December OOH' + suffix)\n",
    "df46 = pd.read_csv(path_files_2024 + 'AB Updated MMM Q4 2024 US Data - Nov OOH' + suffix)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df13.to_csv(path_files_2024 + 'US_Bumble_Anything Goes_Dating Exclusivity_2024 AP' + suffix, index=False)\n",
    "df12.to_csv(path_files_2024 + 'US_Bumble_Audio_Q2 2024' + suffix, index=False)\n",
    "df11.to_csv(path_files_2024 + 'US_Bumble_Dating Sunday_January 2024' + suffix, index=False)\n",
    "df10.to_csv(path_files_2024 + 'US_Bumble_SPAN_2024 AP' + suffix, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def df_transfos(df_dict):\n",
    "    df_spend_by_media_quarter = pd.DataFrame(columns=['Channel', 'quarter_year', 'Spend'])\n",
    "    for key in df_dict:\n",
    "        df = pd.read_csv(df_dict[key] + key + suffix)\n",
    "        df.columns = ['Channel', 'Country', 'DMA', 'Campaign', 'Quarter', 'Date', 'Impressions', 'Spend']\n",
    "        df['source_csv'] = key\n",
    "        # print(df.head())\n",
    "        df.Date = df.Date.astype('datetime64[ns]')\n",
    "        df['quarter_nb'] = df.Date.dt.quarter.astype(str)\n",
    "        df['year_nb'] = df.Date.dt.year.astype(str)\n",
    "        df['quarter_year'] = df['year_nb'] + '-' + df['quarter_nb']\n",
    "\n",
    "        df_spend_temp = df.groupby(['source_csv', 'Channel', 'quarter_year'], as_index = False)['Spend'].sum()\n",
    "\n",
    "        df_spend_by_media_quarter = pd.concat([df_spend_by_media_quarter, df_spend_temp], ignore_index=True)\n",
    "        \n",
    "    return df_spend_by_media_quarter\n",
    "\n",
    "df_spend_grouped = df_transfos(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GoogleSheetData()\n",
    "gs.write_dataframe(df_spend_grouped, \"1JjhkNomf5k3GFmrGw0E8Elz2bLyIKrerqTW9Rq0Fke4\", \"Python_Script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df47 = pd.read_csv(path_files_2024 + 'Net New 2024 MMM Spend - Net New Items.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Country</th>\n",
       "      <th>DMA</th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Date</th>\n",
       "      <th>Impressions</th>\n",
       "      <th>Spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sports Sponsorships</td>\n",
       "      <td>US</td>\n",
       "      <td>NYC</td>\n",
       "      <td>Liberty Parade</td>\n",
       "      <td>Q4</td>\n",
       "      <td>2024-10-14</td>\n",
       "      <td>0</td>\n",
       "      <td>318,099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sports Sponsorships</td>\n",
       "      <td>US</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NY Liberty</td>\n",
       "      <td>Q3</td>\n",
       "      <td>2024-08-20</td>\n",
       "      <td>0</td>\n",
       "      <td>25,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports Sponsorships</td>\n",
       "      <td>US</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NY Liberty</td>\n",
       "      <td>Q3</td>\n",
       "      <td>2024-08-22</td>\n",
       "      <td>0</td>\n",
       "      <td>25,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sports Sponsorships</td>\n",
       "      <td>US</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NY Liberty</td>\n",
       "      <td>Q3</td>\n",
       "      <td>2024-08-24</td>\n",
       "      <td>0</td>\n",
       "      <td>25,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sports Sponsorships</td>\n",
       "      <td>US</td>\n",
       "      <td>NYC</td>\n",
       "      <td>NY Liberty</td>\n",
       "      <td>Q3</td>\n",
       "      <td>2024-09-08</td>\n",
       "      <td>0</td>\n",
       "      <td>25,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Channel Country  DMA        Campaign Quarter        Date  \\\n",
       "0  Sports Sponsorships      US  NYC  Liberty Parade      Q4  2024-10-14   \n",
       "1  Sports Sponsorships      US  NYC      NY Liberty      Q3  2024-08-20   \n",
       "2  Sports Sponsorships      US  NYC      NY Liberty      Q3  2024-08-22   \n",
       "3  Sports Sponsorships      US  NYC      NY Liberty      Q3  2024-08-24   \n",
       "4  Sports Sponsorships      US  NYC      NY Liberty      Q3  2024-09-08   \n",
       "\n",
       "   Impressions    Spend  \n",
       "0            0  318,099  \n",
       "1            0   25,000  \n",
       "2            0   25,000  \n",
       "3            0   25,000  \n",
       "4            0   25,000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df47.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Channel         object\n",
       "Country         object\n",
       "DMA             object\n",
       "Campaign        object\n",
       "Quarter         object\n",
       "Date            object\n",
       "Impressions      int64\n",
       "Spend          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df47.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "df1.Date2 = df1.Date2.astype('datetime64[ns]')\n",
    "df1['year'] = df1.Date2.dt.year.astype(str)\n",
    "df_test = df1[df1['year']=='2024']\n",
    "# df_test['test'] = df_test['Date2'] - datetime.timedelta(days=366)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df47['Spend'] = df47['Spend'].astype(\"str\")\n",
    "df47['Spend'] = df47['Spend'].str.replace('$', '')\n",
    "df47['Spend'] = df47['Spend'].str.replace(',', '')\n",
    "df47['Spend'] = df47['Spend'].str.replace('\"', '')\n",
    "df47['Spend'] = df47['Spend'].str.replace(' -', '0')\n",
    "df47['Spend'] = df47['Spend'].astype(\"float\")\n",
    "# df_final['Impressions'] = df_final['Impressions'].str.replace(',', '')\n",
    "# df_final['Impressions'] = df_final['Impressions'].str.replace('\"', '')\n",
    "# df_final['Impressions'] = df_final['Impressions'].str.replace('-', '0')\n",
    "# df_final['Impressions'] = df_final['Impressions'].str.replace('.00', '')\n",
    "# df_final['Impressions'] = df_final['Impressions'].fillna('0')\n",
    "# df_final['Impressions'] = df_final['Impressions'].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4626434.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df47['Spend'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df47.to_csv(path_files_2024 + 'Net New 2024 MMM Spend - Net New Items' + suffix, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
